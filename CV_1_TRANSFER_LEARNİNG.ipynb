{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d5fabb-0b22-444c-814e-57f96888d536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db79a12-b904-43fa-a2df-527d5f946035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 4 classes.\n",
      "Found 160 images belonging to 4 classes.\n",
      "Found 5120 images belonging to 4 classes.\n",
      "Found 1280 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "def load_data(data_path):\n",
    "    train_data = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_data = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "train_orig, val_orig = load_data(\"C:/Users/PC/output_original_images\")\n",
    "train_proc, val_proc = load_data(\"C:/Users/PC/output_processed_images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f6c1a-03ea-49a6-99a9-4da1c1ff5ba9",
   "metadata": {},
   "source": [
    "Bu Python kodu, görüntü veri setlerini yüklemek ve ön işlemek için Keras'ın `ImageDataGenerator` sınıfını kullanır. İlk olarak, `IMG_SIZE` değişkeni 224 olarak ve `BATCH_SIZE` değişkeni 32 olarak tanımlanır. `ImageDataGenerator` nesnesi, veri artırma ve ön işleme adımlarını yapılandırmak için oluşturulur. Bu örnekte, veri setinin %20'si doğrulama için ayrılır (`validation_split=0.2`) ve tüm görüntü pikselleri 0 ile 1 arasına ölçeklendirilir (`rescale=1./255`).\r\n",
    "\r\n",
    "`load_data` adında bir fonksiyon tanımlanır. Bu fonksiyon, bir veri yolu (`data_path`) alır ve bu yoldaki görüntüleri eğitim ve doğrulama kümelerine ayırarak yükler. `flow_from_directory` metodu kullanılır. Bu metot, belirtilen dizindeki alt klasörleri (kategorileri) otomatik olarak tanır ve görüntüleri bu kategorilere göre etiketler. `target_size` parametresi, tüm görüntülerin belirtilen boyuta (224x224) yeniden boyutlandırılmasını sağlar. `batch_size`, her bir eğitim veya doğrulama adımında kaç görüntü işleneceğini belirler. `class_mode='categorical'` parametresi, sınıf etiketlerinin one-hot encoding formatında olmasını sağlar. `subset` parametresi, veri setinin hangi bölümünün (eğitim veya doğrulama) yükleneceğini belirtir. `shuffle=True` parametresi, eğitim verisinin karıştırılmasını sağlarken, doğrulama verisinin sırası korunur (`shuffle=False`).\r\n",
    "\r\n",
    "Son olarak, `load_data` fonksiyonu iki kez çağrılır. İlk çağrı, \"C:/Users/PC/output_original_images\" yolundaki orijinal görüntüleri yükleyerek `train_orig` (eğitim verisi) ve `val_orig` (doğrulama verisi) değişkenlerine atar. İkinci çağrı ise \"C:/Users/PC/output_processed_images\" yolundaki işlenmiş (boyutlandırılmış ve potansiyel olarak başka işlemlerden geçmiş) görüntüleri yükleyerek `train_proc` (eğitim verisi) ve `val_proc` (doğrulama verisi) değişkenlerine atar. Bu şekilde, hem orijinal hem de işlenmiş görüntü veri setleri ayrı ayrı yüklenerek model eğitimi ve değerlendirmesi için hazır hale getirilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9539fc80-c793-4564-be3c-46d30fea90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def build_model():\n",
    "    base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5bb26-30e1-4383-b0eb-52a15d88cc9e",
   "metadata": {},
   "source": [
    "Bu Python kodu, görüntü sınıflandırması için MobileNetV2 tabanlı bir derin öğrenme modeli oluşturur. Önceden eğitilmiş MobileNetV2 katmanları dondurulur ve üzerine global ortalama havuzlama, iki adet düzenlileştirilmiş (L2), batch normalization uygulanmış ve dropout katmanlarına sahip yoğun katmanlar eklenir. Son olarak, 4 sınıflı çıktı için softmax aktivasyonlu bir yoğun katman kullanılır. Model, Adam optimizasyon algoritması ve kategorik çapraz entropi kaybı ile derlenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a511e5e6-f7e0-4f00-88d2-5bd99f330ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "20/20 [==============================] - 17s 503ms/step - loss: 2.4193 - accuracy: 0.2969 - val_loss: 1.8145 - val_accuracy: 0.4750\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 9s 440ms/step - loss: 2.0837 - accuracy: 0.4281 - val_loss: 1.7050 - val_accuracy: 0.5312\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 9s 428ms/step - loss: 1.8033 - accuracy: 0.5250 - val_loss: 1.6306 - val_accuracy: 0.5562\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 9s 429ms/step - loss: 1.7234 - accuracy: 0.5688 - val_loss: 1.5856 - val_accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 1.6638 - accuracy: 0.5906 - val_loss: 1.5469 - val_accuracy: 0.6250\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 1.5584 - accuracy: 0.6469 - val_loss: 1.5073 - val_accuracy: 0.6625\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 1.5050 - accuracy: 0.6438 - val_loss: 1.4844 - val_accuracy: 0.6687\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 1.4706 - accuracy: 0.6656 - val_loss: 1.4445 - val_accuracy: 0.6750\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 1.4042 - accuracy: 0.6875 - val_loss: 1.4190 - val_accuracy: 0.6812\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 9s 437ms/step - loss: 1.3397 - accuracy: 0.6969 - val_loss: 1.4011 - val_accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "model_orig = build_model()\n",
    "history_orig = model_orig.fit(train_orig, validation_data=val_orig, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34c6fe-0d0d-4b5c-8b7f-cf2ad6271aa6",
   "metadata": {},
   "source": [
    "Bu Python kodu, önceden tanımlanmış olan `build_model()` fonksiyonunu çağırarak `model_orig` adında bir derin öğrenme modeli oluşturur. Ardından, bu modeli eğitmek için `fit()` metodu kullanılır. Eğitim verisi olarak `train_orig` (orijinal görüntülerden oluşturulmuş eğitim veri üreteci) ve doğrulama verisi olarak `val_orig` (orijinal görüntülerden oluşturulmuş doğrulama veri üreteci) kullanılır. Eğitim işlemi toplamda 10 epoch boyunca gerçekleştirilir. Her bir epoch, tüm eğitim verisinin bir kez model tarafından geçirilmesini ifade eder. Eğitim süresince, modelin eğitim verisi üzerindeki performansı ve doğrulama verisi üzerindeki performansı (kayıp ve doğruluk gibi metrikler) takip edilir ve bu bilgiler `history_orig` değişkenine kaydedilir. Bu değişken, eğitim sürecinin analiz edilmesi ve modelin performansının değerlendirilmesi için kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53655c95-b1f8-4804-8528-f89e9ced59a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "160/160 [==============================] - 72s 415ms/step - loss: 2.3576 - accuracy: 0.3502 - val_loss: 1.6943 - val_accuracy: 0.5203\n",
      "Epoch 2/15\n",
      "160/160 [==============================] - 68s 425ms/step - loss: 2.0130 - accuracy: 0.4424 - val_loss: 1.5352 - val_accuracy: 0.6086\n",
      "Epoch 3/15\n",
      "160/160 [==============================] - 68s 425ms/step - loss: 1.8654 - accuracy: 0.5008 - val_loss: 1.4350 - val_accuracy: 0.6656\n",
      "Epoch 4/15\n",
      "160/160 [==============================] - 67s 417ms/step - loss: 1.7821 - accuracy: 0.5195 - val_loss: 1.3927 - val_accuracy: 0.6875\n",
      "Epoch 5/15\n",
      "160/160 [==============================] - 67s 418ms/step - loss: 1.6872 - accuracy: 0.5576 - val_loss: 1.3933 - val_accuracy: 0.6789\n",
      "Epoch 6/15\n",
      "160/160 [==============================] - 66s 416ms/step - loss: 1.6496 - accuracy: 0.5686 - val_loss: 1.3523 - val_accuracy: 0.6945\n",
      "Epoch 7/15\n",
      "160/160 [==============================] - 67s 418ms/step - loss: 1.5707 - accuracy: 0.5953 - val_loss: 1.2965 - val_accuracy: 0.7234\n",
      "Epoch 8/15\n",
      "160/160 [==============================] - 67s 418ms/step - loss: 1.5447 - accuracy: 0.6076 - val_loss: 1.2890 - val_accuracy: 0.7281\n",
      "Epoch 9/15\n",
      "160/160 [==============================] - 67s 420ms/step - loss: 1.4971 - accuracy: 0.6258 - val_loss: 1.2856 - val_accuracy: 0.7164\n",
      "Epoch 10/15\n",
      "160/160 [==============================] - 67s 418ms/step - loss: 1.4599 - accuracy: 0.6389 - val_loss: 1.2633 - val_accuracy: 0.7211\n",
      "Epoch 11/15\n",
      "160/160 [==============================] - 67s 417ms/step - loss: 1.4469 - accuracy: 0.6391 - val_loss: 1.2631 - val_accuracy: 0.7289\n",
      "Epoch 12/15\n",
      "160/160 [==============================] - 67s 421ms/step - loss: 1.4179 - accuracy: 0.6496 - val_loss: 1.2394 - val_accuracy: 0.7305\n",
      "Epoch 13/15\n",
      "160/160 [==============================] - 68s 424ms/step - loss: 1.3835 - accuracy: 0.6621 - val_loss: 1.2458 - val_accuracy: 0.7281\n",
      "Epoch 14/15\n",
      "160/160 [==============================] - 67s 421ms/step - loss: 1.3716 - accuracy: 0.6639 - val_loss: 1.2208 - val_accuracy: 0.7422\n",
      "Epoch 15/15\n",
      "160/160 [==============================] - 67s 417ms/step - loss: 1.3297 - accuracy: 0.6807 - val_loss: 1.1959 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "model_proc = build_model()\n",
    "history_proc = model_proc.fit(train_proc, validation_data=val_proc, epochs=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c7204-23dd-4d22-8f4d-db12208c3bb7",
   "metadata": {},
   "source": [
    "Bu Python kodu, önceden tanımlanmış olan `build_model()` fonksiyonunu kullanarak `model_proc` adında yeni bir derin öğrenme modeli oluşturur. Bu model, orijinal görüntülerle eğitilen `model_orig` modelinden ayrı bir örnektir. Ardından, bu yeni model, `fit()` metodu aracılığıyla eğitilir. Eğitim için, işlenmiş görüntülerden oluşturulmuş eğitim veri kümesi (`train_proc`) ve doğrulama veri kümesi (`val_proc`) kullanılır. Model, bu veri kümeleri üzerinde 15 epoch boyunca eğitilir. Her bir epoch, tüm eğitim verisinin model tarafından bir kez işlenmesi anlamına gelir. Eğitim süresince, modelin hem eğitim hem de doğrulama verisi üzerindeki performansı (örneğin, kayıp ve doğruluk değerleri) izlenir ve bu bilgiler `history_proc` değişkeninde saklanır. Bu `history_proc` nesnesi, eğitim sürecinin sonunda modelin performansını değerlendirmek ve görselleştirmek için kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82c4979-b2e9-45ff-8f15-8e56ab04da6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 350ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CNV       0.76      0.88      0.81        40\n",
      "         DME       0.79      0.55      0.65        40\n",
      "      DRUSEN       0.59      0.60      0.59        40\n",
      "      NORMAL       0.69      0.78      0.73        40\n",
      "\n",
      "    accuracy                           0.70       160\n",
      "   macro avg       0.71      0.70      0.70       160\n",
      "weighted avg       0.71      0.70      0.70       160\n",
      "\n",
      "40/40 [==============================] - 14s 305ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CNV       0.80      0.84      0.82       320\n",
      "         DME       0.84      0.68      0.75       320\n",
      "      DRUSEN       0.65      0.72      0.68       320\n",
      "      NORMAL       0.74      0.76      0.75       320\n",
      "\n",
      "    accuracy                           0.75      1280\n",
      "   macro avg       0.76      0.75      0.75      1280\n",
      "weighted avg       0.76      0.75      0.75      1280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, val_data):\n",
    "    val_data.reset()\n",
    "    predictions = model.predict(val_data)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = val_data.classes\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=val_data.class_indices.keys()))\n",
    "    return classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "report_orig = evaluate_model(model_orig, val_orig)\n",
    "report_proc = evaluate_model(model_proc, val_proc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "700bd5c9-607d-4a4f-8877-d5b5909d3805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Precision</th>\n",
       "      <th>Proc_Precision</th>\n",
       "      <th>Orig_Recall</th>\n",
       "      <th>Proc_Recall</th>\n",
       "      <th>Orig_F1</th>\n",
       "      <th>Proc_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.795252</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.68125</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.751724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.648045</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.684366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.744615</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.750388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.756593</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.695754</td>\n",
       "      <td>0.750577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.756593</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.695754</td>\n",
       "      <td>0.750577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Orig_Precision  Proc_Precision  Orig_Recall  Proc_Recall  \\\n",
       "0                   0.760870        0.795252        0.875      0.83750   \n",
       "1                   0.785714        0.838462        0.550      0.68125   \n",
       "2                   0.585366        0.648045        0.600      0.72500   \n",
       "3                   0.688889        0.744615        0.775      0.75625   \n",
       "accuracy            0.700000        0.750000        0.700      0.75000   \n",
       "macro avg           0.705210        0.756593        0.700      0.75000   \n",
       "weighted avg        0.705210        0.756593        0.700      0.75000   \n",
       "\n",
       "               Orig_F1   Proc_F1  \n",
       "0             0.813953  0.815830  \n",
       "1             0.647059  0.751724  \n",
       "2             0.592593  0.684366  \n",
       "3             0.729412  0.750388  \n",
       "accuracy      0.700000  0.750000  \n",
       "macro avg     0.695754  0.750577  \n",
       "weighted avg  0.695754  0.750577  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_orig = pd.DataFrame(report_orig).transpose()\n",
    "df_proc = pd.DataFrame(report_proc).transpose()\n",
    "\n",
    "comparison_df = pd.concat([df_orig['precision'], df_proc['precision'],\n",
    "                           df_orig['recall'], df_proc['recall'],\n",
    "                           df_orig['f1-score'], df_proc['f1-score']], axis=1)\n",
    "\n",
    "comparison_df.columns = ['Orig_Precision', 'Proc_Precision', \n",
    "                         'Orig_Recall', 'Proc_Recall', \n",
    "                         'Orig_F1', 'Proc_F1']\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f53b5-bff1-4560-a682-ba91e7e4161f",
   "metadata": {},
   "source": [
    "Ödevde bizden istendiği gibi başarı artışı gözlemlenmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7373eba-aa41-43f8-8abd-3ff87f276e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
